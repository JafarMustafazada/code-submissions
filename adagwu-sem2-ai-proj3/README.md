## Overview
The core functionality is based on a minimax algorithm—with an option for alpha-beta pruning—and includes various heuristics and optimizations to efficiently explore the game tree, determine candidate moves, and dynamically adjust search depth based on elapsed time. Multithreading support is also available to improve performance.

Here is github link of c++ code: [cpp header file](./cpp_ttt_agent/include/ttt_agent/ttt_agent2.hpp)!

Here is github link of c++ code project folder: [CMake Project Folder](./cpp_ttt_agent/)

---

## Board Representation and Move Handling

### Key Functions
- **Cacshing:** `boardKey()`: Produces a unique string key based on the current board state, which is used for caching evaluations.
- **Move Generation:** The `getCandidateMoves()` function restricts search to cells in proximity (default radius 1) of already-played moves.
## Evaluation (Heuristic) Function
- **Heuristic-Based Sorting:** Candidate moves are sorted based on their Manhattan distance to the board’s center using the `heuristic2()` function. Moves closer to the center are favored, as they typically hold strategic value.
- **`checkAllDangers(const pii &move, pii &endpoint, char p = E)`**
**What It Does:**  
	Determines whether a move is “dangerous” by checking if it is close to creating a win for the opponent. It examines multiple directions (horizontal, vertical, and the two diagonals) and returns:
	- `0` if there is no immediate threat,
	- A positive integer if the move is one step away from winning (representing the number of such dangerous sequences),
	- `INT_MAX` if the move wins the game (if danger is 2 or more, then it is also game winning move).
---

### Key Methods Involved
3. **Combined Use in Evaluation:**  
- Both `heuristic2` and `checkAllDangers` are utilized in the minimax algorithms to evaluate non-terminal positions. While `heuristic2` gives a quick, positional score, `checkAllDangers` serves as the more critical evaluation by detecting imminent win or loss conditions.

---

## Minimax/Adversarial Search Algorithm

### Algorithm Structure

1. **Minimax Functions:**
- **`minimax()` and `minimax_alpha_beta()`**
	- **Purpose:**  
	Both functions recursively evaluate game states from the current position down to a given search depth (or until a terminal state is reached, such as a full board or a winning move). The only difference is that `minimax_alpha_beta()` incorporates alpha-beta pruning to eliminate branches that will not influence the final decision.
	- **Additional parameters:** 
	- The start time and a time limit to ensure the search does not run indefinitely
- **Terminal Conditions:**  
	The recursion stops when one of the following is true:
	- A winning move is detected via `checkAllDangers()` (resulting in an immediate return of `WIN_SCORE` or `LOSE_SCORE`).
	- The board is full.
	- The maximum search depth is reached.
- **State Caching:**  
	A cache (implemented as an unordered map using the board’s key generated by `boardKey()`) is used to save evaluated game states. This avoids re-evaluating the same board configuration multiple times, thereby speeding up the search.

### Alpha-Beta Pruning
- **Integration:**  
In the `minimax_alpha_beta()` function, the algorithm uses two parameters—`alpha` (best already explored option along the path to the root for the maximizer) and `beta` (best for the minimizer). The search stops exploring a branch when it becomes clear that it cannot result in a better outcome than a previously explored branch.
- **Benefits:**  
This technique greatly reduces the number of nodes that must be evaluated in the minimax tree, leading to significant performance improvements in deeper search trees.

---

## Tricks and Performance Improvements

### Dynamic Depth Adjustment
- **Time Management:**  
Both in the single-threaded (`minimaxBest()`) and multi-threaded (`minimaxBestThreading()`) implementations, the algorithm tracks the elapsed time during evaluation.  
- If the search is progressing quickly (i.e., if the elapsed time is less than an eighth of the allowed time), the search depth is increased to potentially find a better move.
- Conversely, if the search is taking too long, the depth is reduced.
- **Rationale:**  
This dynamic adjustment helps the agent balance between quality of move selection and computational constraints.

### Candidate Move Pruning
- **Localized Search:**  
The generation of candidate moves is limited to positions near already played moves. This significantly reduces the search space, allowing the minimax algorithm to focus on the most relevant parts of the board.

### Caching of Evaluations
- **Board State Cache:**  
The use of a cache (a hash table keyed by the board representation) prevents redundant evaluations of already-seen game states. This memoization is crucial in reducing the exponential time complexity typical of naive minimax searches.

### Multithreading
- **Performance Gain:**  
This parallelization can lead to faster evaluation times, especially on systems with multiple cores, as move evaluations are independent and can be processed concurrently.

### Time Limit Checks
- **Iteration Breaks:**  
In each loop of the minimax recursion and during candidate move evaluations, the algorithm constantly checks if the elapsed time has reached a specified limit. If so, it exits early to prevent overshooting the computation time, providing a safeguard against long computations.

---

## Summary
- **Evaluation Function:**  
Uses Manhattan distance (via `heuristic2`) and a danger-checking mechanism (via `checkAllDangers`) to score moves.  
- **Minimax Search:**  
Implements a recursive minimax approach with an option for alpha-beta pruning, alternating between maximizing and minimizing players while leveraging caching to avoid duplicate evaluations.
- **Performance Tricks:**  
Several techniques—including candidate move pruning, dynamic depth adjustment based on timing, caching of board evaluations, and multithreading—are used to improve the efficiency and responsiveness of the algorithm.
